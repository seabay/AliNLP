{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ali.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2DThheVCSE69",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCxPUxjZseZN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "accelerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFLRFF99R6CK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, OrderedDict\n",
        "import re\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import PackedSequence,pack_padded_sequence\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EQ1faqTTJTy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 安装 PyDrive 操作库，该操作每个 notebook 只需要执行一次\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 授权登录，仅第一次的时候会鉴权\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0iYUJ9kTUxf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 列出根目录的所有文件\n",
        "# \"q\" 查询条件教程详见：https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPnkftXqUJOf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# '目录 id' in parents\n",
        "file_list = drive.ListFile({'q': \"'16zfnt8Cnuznzwj2RHGrxvyfyA6iQPRXx' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QE8YA5PwU1pV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "file = drive.CreateFile({'id': \"1py3JAFOLOH2lM-lOqYyP_LfqaImlOqL_\"}) \n",
        "#这里的下载操作只是缓存，不会在你的Google Drive 目录下多下载一个文件\n",
        "file.GetContentFile('data.csv', \"text/csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--NHxEVRVEW_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv', sep='\\t', names=['number', \"sen1\", \"sen2\", \"label\"], skipinitialspace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mnBj_KKVKFW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7rrWLo1SZbY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def normalize_string(s):\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxcCgkzsVd6z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "X1_r = list(map(normalize_string, df.sen1.tolist()))\n",
        "X2_r = list(map(normalize_string, df.sen2.tolist()))\n",
        "y_r = df.label.tolist()\n",
        "print(len(X1_r), len(X2_r), len(y_r))\n",
        "print(X1_r[0], \"@@@@\", X2_r[0], \"@@@@\",y_r[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7oGud6MVi7x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocab = list(set(flatten(X1_r + X2_r)))\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNQj-kWjVkFi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source2index = {'<PAD>':0,'<UNK>':1,'<s>':2,'</s>':3}\n",
        "for vo in vocab:\n",
        "    if vo not in source2index.keys():\n",
        "        source2index[vo]=len(source2index)\n",
        "index2source = {v:k for k,v in source2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW1vMMwZVnVS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "index2source[source2index[\",\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpXO_1YKV6HE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCH=50\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_SIZE = 128\n",
        "HIDDEN_SIZE = 256\n",
        "LR = 0.01\n",
        "DECODER_LEARNING_RATIO=5.0\n",
        "RESCHEDULED=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yfl0IVKNSNSG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
        "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WU6658BRsl8I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q_C1LkOa2Zru",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "LongTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1VNP_OnfSZQM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def getBatch(batch_size,train_data):\n",
        "    random.shuffle(train_data)\n",
        "    sindex=0\n",
        "    eindex=batch_size\n",
        "    while eindex < len(train_data):\n",
        "        batch = train_data[sindex:eindex]\n",
        "        temp = eindex\n",
        "        eindex = eindex+batch_size\n",
        "        sindex = temp\n",
        "        yield batch\n",
        "    \n",
        "    if eindex >= len(train_data):\n",
        "        batch = train_data[sindex:]\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5O-H4hidSV9R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_index):\n",
        "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<unk>\"], seq))\n",
        "    return LongTensor(idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfJO_v1nVp5t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X1_p, X2_p = [],[]\n",
        "ta_p = []\n",
        "\n",
        "for s1, s2, ta in zip(X1_r, X2_r, y_r):\n",
        "    X1_p.append(prepare_sequence(s1,source2index).view(1,-1))\n",
        "    X2_p.append(prepare_sequence(s2,source2index).view(1,-1))\n",
        "    ta_p.append(ta)\n",
        "    \n",
        "data = list(zip(X1_p, X2_p, ta_p))\n",
        "random.shuffle(data)\n",
        "train_data = data[:30000]\n",
        "test_data = data[30000:]\n",
        "\n",
        "print(train_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqhQUb2bSZmF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def pad_to_batch(batch,x_to_ix):\n",
        "    \n",
        "    sorted_batch =  sorted(batch, key=lambda b:b[0].size(1),reverse=True) # sort by len\n",
        "    \n",
        "    x1, x2, y = list(zip(*sorted_batch))\n",
        "    max_x1 = max([s.size(1) for s in x1])\n",
        "    max_x2 = max([s.size(1) for s in x2])\n",
        "    \n",
        "    x1_p, x2_p, y_p = [],[],[]\n",
        "    for i in range(len(batch)):\n",
        "      \n",
        "        if x1[i].size(1)<max_x1:\n",
        "            x1_p.append(torch.cat( [ Variable(x1[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x1-x1[i].size(1)))).view(1,-1) ],1))\n",
        "        else:\n",
        "            x1_p.append(Variable(x1[i]))\n",
        "        \n",
        "        if x2[i].size(1)<max_x2:\n",
        "            #v = Variable(LongTensor([x_to_ix['<PAD>']]*(max_x2-x2[i].size(1)))).view(1,-1)\n",
        "            #print(torch.cat((Variable(x2[i]), v), 1))\n",
        "            x2_p.append(torch.cat( [ Variable(x2[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x2-x2[i].size(1)))).view(1,-1) ],1))\n",
        "        else:\n",
        "            x2_p.append(Variable(x2[i]))\n",
        "        \n",
        "    x1_var = torch.cat(x1_p, 0)\n",
        "    x2_var = torch.cat(x2_p, 0)\n",
        "    target_var = Variable(LongTensor(y))\n",
        "    x1_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x1_var]\n",
        "    x2_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x2_var]\n",
        "    \n",
        "    return x1_var, x2_var, target_var, x1_len, x2_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wtnr6T6sSiSc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "batch = next(getBatch(BATCH_SIZE,train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEuyk5eOWEuS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pbatch = pad_to_batch(batch,source2index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V2LfurtTRj71",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pbatch[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tgDAdycqrZBl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EncoderV(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size,hidden_size, n_layers=1,bidirec=False):\n",
        "        super(EncoderV, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        \n",
        "        if bidirec:\n",
        "            self.n_direction = 2 \n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
        "        else:\n",
        "            self.n_direction = 1\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
        "    \n",
        "    def init_hidden(self,inputs):  # input.size(0) = batch_size\n",
        "        hidden = Variable(torch.zeros(self.n_layers*self.n_direction,inputs.size(0),self.hidden_size))\n",
        "        return hidden.cuda() if USE_CUDA else hidden\n",
        "    \n",
        "    def init_weight(self):\n",
        "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
        "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
        "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
        "    \n",
        "    def forward(self, x, x_len):\n",
        "        \"\"\"\n",
        "        sequence -> sort -> pad and pack ->process using RNN -> unpack ->unsort\n",
        "\n",
        "        :param x: Variable\n",
        "        :param x_len: numpy list\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        \n",
        "        hidden = self.init_hidden(x)\n",
        "        \n",
        "        \"\"\"sort\"\"\"\n",
        "        x_sort_idx = np.argsort(x_len)[::-1]\n",
        "        x_unsort_idx = LongTensor(np.argsort(x_sort_idx))\n",
        "        x_len = np.array(x_len)[x_sort_idx]\n",
        "        x = x[LongTensor(x_sort_idx.copy())]\n",
        "      \n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        \"\"\"pack\"\"\"\n",
        "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True)\n",
        "                \n",
        "        \"\"\"process using RNN\"\"\"\n",
        "        out_pack, ht = self.gru(x_emb_p, hidden)\n",
        "        \n",
        "        \"\"\"unsort: h\"\"\"\n",
        "        ht = torch.transpose(ht, 0, 1)[\n",
        "            x_unsort_idx]  # (num_layers * num_directions, batch, hidden_size) -> (batch, ...)\n",
        "        ht = torch.transpose(ht, 0, 1)\n",
        "\n",
        "        #print(\"ht\", ht.shape)\n",
        "        if self.n_layers>1:\n",
        "            if self.n_direction==2:\n",
        "                ht = ht[-2:]\n",
        "                return out_pack, torch.cat((ht[0], ht[1]),1)\n",
        "            else:\n",
        "                ht = ht[-1]\n",
        "                return out_pack, ht\n",
        "\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQucPtqErioh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder1, encoder2, hidden_size):\n",
        "        \n",
        "        super(Model, self).__init__()\n",
        "        self.encoder1 = encoder1\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_size*4, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, 2)\n",
        "        \n",
        "    def init_weight(self):\n",
        "        \n",
        "        self.encoder1.init_weight()\n",
        "        #self.fc1.weight = nn.init.xavier_uniform(self.fc1.weight)\n",
        "        #self.fc2.weight = nn.init.xavier_uniform(self.fc2.weight)\n",
        "        \n",
        "    def forward(self, sen1, sen2, sen1_lengths, sen2_lengths):\n",
        "             \n",
        "        outputs_1, hidden_c1 = encoder1(sen1,sen1_lengths)\n",
        "        outputs_2, hidden_c2 = encoder1(sen2,sen2_lengths)\n",
        "        \n",
        "        hidden = torch.cat((hidden_c1, hidden_c2), 1).squeeze(1)  # batch * 2hidden\n",
        "        out = self.fc1(hidden)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQkE4gfMrlur",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "encoder1 = EncoderV(len(source2index),EMBEDDING_SIZE,HIDDEN_SIZE,2,True)\n",
        "if USE_CUDA:\n",
        "    encoder1 = encoder1.cuda()\n",
        "    \n",
        "model = Model(encoder1, encoder1, HIDDEN_SIZE)\n",
        "model.init_weight()\n",
        "\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=LR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmBOOTPhxVTF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x08j3uuj4Igt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i,p in enumerate(model.parameters()):\n",
        "    if p.requires_grad:\n",
        "        print(i, \":\", p.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mVbrE_la4KNC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list(model.parameters())[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXoRlKFZ4i4H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list(model.parameters())[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7u1jwcR6rv8D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### test \n",
        "for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
        "    \n",
        "    # sen1 = batch * l\n",
        "    sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
        "    print(\"sen1 size: \", sen1.shape)\n",
        "    #input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in sen1]).view(sen1.size(0),-1)\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward + Backward + Optimize\n",
        "    outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "    print('outputs', outputs.size())\n",
        "    print('targets', targets.size())\n",
        "    loss = criterion(outputs, targets)\n",
        "    print('loss', loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYyrQx1qsZUl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfa0742a-41ac-4888-eb9b-b82b4a977a6d"
      },
      "cell_type": "code",
      "source": [
        "total_step = round(len(train_data) / BATCH_SIZE)\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    \n",
        "    total_loss = []\n",
        "    \n",
        "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
        "        sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss.append(loss.data[0])\n",
        "\n",
        "        if (i+1) % 20 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                       .format(epoch+1, EPOCH, i+1, total_step, loss.data[0]))\n",
        "     \n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, EPOCH, np.mean(total_loss)))\n",
        "    \n",
        "    if RESCHEDULED == False and epoch  == EPOCH//2:\n",
        "        LR *= 0.01\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "        RESCHEDULED = True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [13/50], Step [420/469], Loss: 0.5049\n",
            "Epoch [13/50], Step [440/469], Loss: 0.5048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RDPcrit3PT4X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def infer(sens):\n",
        "    \n",
        "    outputs = model(sens[0], sens[1], [sens[0].size(1)], [sens[1].size(1)])  \n",
        "    return np.argmax(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJgnhA-4QKlp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#test = random.choice(train_data)\n",
        "#test = random.sample(train_data, 5)\n",
        "\n",
        "sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(test,source2index)\n",
        "outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "\n",
        "predict = np.array(np.argmax(outputs.data, 1))\n",
        "targets = np.array(targets.data)\n",
        "print(\"Predict:\", predict)\n",
        "print(\"Truth:\", targets)\n",
        "print(\"Correct: \", np.sum(predict == targets))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoX2Ok3VXHxY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "print(\"confusion_matrix: \\n\" ,confusion_matrix(predict, targets)\n",
        "print(precision_score(predict, targets))\n",
        "print(recall_score(predict, targets))\n",
        "print(f1_score(predict, targets))\n",
        "\n",
        "## tn fp\n",
        "## fn tp"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}