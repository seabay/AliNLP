{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ali.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2DThheVCSE69",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCxPUxjZseZN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1d31f9a-4355-47da-eed1-b9029b0b1ac7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526253135918,
          "user_tz": 240,
          "elapsed": 878,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "accelerator"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cu80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "zFLRFF99R6CK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, OrderedDict\n",
        "import re\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import PackedSequence,pack_padded_sequence\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EQ1faqTTJTy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 安装 PyDrive 操作库，该操作每个 notebook 只需要执行一次\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 授权登录，仅第一次的时候会鉴权\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0iYUJ9kTUxf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a0e89d95-8941-4226-f411-9b22d43264fd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254616995,
          "user_tz": 240,
          "elapsed": 896,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 列出根目录的所有文件\n",
        "# \"q\" 查询条件教程详见：https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: data, id: 16zfnt8Cnuznzwj2RHGrxvyfyA6iQPRXx, mimeType: application/vnd.google-apps.folder\n",
            "title: Colab Notebooks, id: 1DDn16_H4dL75WfkYDpWNxRzqJkH6uvsk, mimeType: application/vnd.google-apps.folder\n",
            "title: 02 - email-templates.png, id: 0BzICsNHMK-GFdnZhNFBoVXdobkhBa3h2eUtwbXY1ek15Sk53, mimeType: image/png\n",
            "title: ATEC-Alipay, id: 1UyfXNCoPHh73E4jO-pgombXQShfYkzAVgGfSUnU7OAE, mimeType: application/vnd.google-apps.document\n",
            "title: The Annotated _Attention is All You Need_.ipynb, id: 1zIkaTyyRtMY0qRTuUxe9J10xR3S9J5Xc, mimeType: application/vnd.google.colab\n",
            "title: Copy of mixture_of_softmaxes.ipynb, id: 1HiJvBimCdWvFP7SoLs9bWNR-JbCQSRsG, mimeType: application/vnd.google.colab\n",
            "title: Copy of Hello, Colaboratory, id: 0BzICsNHMK-GFcFBrQkV2UXpMVGM, mimeType: application/vnd.google.colab\n",
            "title: Screen Shot 2017-10-12 at 9.35.30 PM.png, id: 0BzICsNHMK-GFMjFrZzQwOHZvYVRiMWgtVlVfSlVRU1FYZmdn, mimeType: image/png\n",
            "title: 2017 Calendar, id: 1jw6VChc9SGayYuK5Zmy2PjaiwWM0tzGFrPG9eatsSNw, mimeType: application/vnd.google-apps.spreadsheet\n",
            "title: Getting started, id: 0BzICsNHMK-GFc3RhcnRlcl9maWxlX2Rhc2hlclYw, mimeType: application/pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zPnkftXqUJOf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5373bca-edbe-4a87-fdd1-99331151f810",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254617893,
          "user_tz": 240,
          "elapsed": 715,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# '目录 id' in parents\n",
        "file_list = drive.ListFile({'q': \"'16zfnt8Cnuznzwj2RHGrxvyfyA6iQPRXx' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: atec_nlp_sim_train.csv, id: 1py3JAFOLOH2lM-lOqYyP_LfqaImlOqL_, mimeType: text/csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QE8YA5PwU1pV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "file = drive.CreateFile({'id': \"1py3JAFOLOH2lM-lOqYyP_LfqaImlOqL_\"}) \n",
        "#这里的下载操作只是缓存，不会在你的Google Drive 目录下多下载一个文件\n",
        "file.GetContentFile('data.csv', \"text/csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--NHxEVRVEW_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv', sep='\\t', names=['number', \"sen1\", \"sen2\", \"label\"], skipinitialspace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mnBj_KKVKFW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "2b2981bb-d4e2-4d10-e952-3a399369bb8b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254620766,
          "user_tz": 240,
          "elapsed": 492,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>sen1</th>\n",
              "      <th>sen2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>﻿怎么更改花呗手机号码</td>\n",
              "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>也开不了花呗，就这样了？完事了</td>\n",
              "      <td>真的嘛？就是花呗付款</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   number             sen1                            sen2  label\n",
              "0       1      ﻿怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号      1\n",
              "1       2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "N7rrWLo1SZbY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def normalize_string(s):\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxcCgkzsVd6z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c5b11024-33e4-4808-ed13-8cd620d54b8c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254621925,
          "user_tz": 240,
          "elapsed": 596,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "X1_r = list(map(normalize_string, df.sen1.tolist()))\n",
        "X2_r = list(map(normalize_string, df.sen2.tolist()))\n",
        "y_r = df.label.tolist()\n",
        "print(len(X1_r), len(X2_r), len(y_r))\n",
        "print(X1_r[0], \"@@@@\", X2_r[0], \"@@@@\",y_r[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39346 39346 39346\n",
            "﻿怎么更改花呗手机号码 @@@@ 我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号 @@@@ 1\n",
            "CPU times: user 126 ms, sys: 3 ms, total: 129 ms\n",
            "Wall time: 131 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b7oGud6MVi7x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a842d462-2881-4623-eac3-7ca30c864b19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254622516,
          "user_tz": 240,
          "elapsed": 465,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocab = list(set(flatten(X1_r + X2_r)))\n",
        "len(vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "cNQj-kWjVkFi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source2index = {'<PAD>':0,'<UNK>':1,'<s>':2,'</s>':3}\n",
        "for vo in vocab:\n",
        "    if vo not in source2index.keys():\n",
        "        source2index[vo]=len(source2index)\n",
        "index2source = {v:k for k,v in source2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW1vMMwZVnVS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89cd7df0-85af-4cf8-f5f9-3206dddeba95",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254623567,
          "user_tz": 240,
          "elapsed": 436,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "index2source[source2index[\",\"]]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "','"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "BpXO_1YKV6HE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCH=50\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_SIZE = 128\n",
        "HIDDEN_SIZE = 256\n",
        "LR = 0.01\n",
        "DECODER_LEARNING_RATIO=5.0\n",
        "RESCHEDULED=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yfl0IVKNSNSG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
        "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WU6658BRsl8I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f266d5e-4197-4a85-9182-347882308cbf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254625820,
          "user_tz": 240,
          "elapsed": 725,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_C1LkOa2Zru",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e42514b-7551-48d1-b7a1-2381b8027f3c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526254626804,
          "user_tz": 240,
          "elapsed": 885,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "LongTensor"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.cuda.LongTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "1VNP_OnfSZQM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def getBatch(batch_size,train_data):\n",
        "    random.shuffle(train_data)\n",
        "    sindex=0\n",
        "    eindex=batch_size\n",
        "    while eindex < len(train_data):\n",
        "        batch = train_data[sindex:eindex]\n",
        "        temp = eindex\n",
        "        eindex = eindex+batch_size\n",
        "        sindex = temp\n",
        "        yield batch\n",
        "    \n",
        "    if eindex >= len(train_data):\n",
        "        batch = train_data[sindex:]\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5O-H4hidSV9R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_index):\n",
        "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<unk>\"], seq))\n",
        "    return LongTensor(idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfJO_v1nVp5t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "746a6bae-dde7-4560-9bdb-dafa972d2877",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526262639072,
          "user_tz": 240,
          "elapsed": 5626,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X1_p, X2_p = [],[]\n",
        "ta_p = []\n",
        "\n",
        "for s1, s2, ta in zip(X1_r, X2_r, y_r):\n",
        "    X1_p.append(prepare_sequence(s1,source2index).view(1,-1))\n",
        "    X2_p.append(prepare_sequence(s2,source2index).view(1,-1))\n",
        "    ta_p.append(ta)\n",
        "    \n",
        "data = list(zip(X1_p, X2_p, ta_p))\n",
        "random.shuffle(data)\n",
        "train_data = data[:30000]\n",
        "test_data = data[30000:]\n",
        "\n",
        "print(train_data[0])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\n",
            "  413  1184   958  1025   309   913   809  1613   227   510  1025  1329   197\n",
            "[torch.cuda.LongTensor of size 1x13 (GPU 0)]\n",
            ", \n",
            "  895  1690   413  1184   172  1050   510  1349  1302  1329  1613   197\n",
            "[torch.cuda.LongTensor of size 1x12 (GPU 0)]\n",
            ", 0)\n",
            "CPU times: user 3.3 s, sys: 1.27 s, total: 4.57 s\n",
            "Wall time: 4.57 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wqhQUb2bSZmF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def pad_to_batch(batch,x_to_ix):\n",
        "    \n",
        "    sorted_batch =  sorted(batch, key=lambda b:b[0].size(1),reverse=True) # sort by len\n",
        "    \n",
        "    x1, x2, y = list(zip(*sorted_batch))\n",
        "    max_x1 = max([s.size(1) for s in x1])\n",
        "    max_x2 = max([s.size(1) for s in x2])\n",
        "    \n",
        "    x1_p, x2_p, y_p = [],[],[]\n",
        "    for i in range(len(batch)):\n",
        "      \n",
        "        if x1[i].size(1)<max_x1:\n",
        "            x1_p.append(torch.cat( [ Variable(x1[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x1-x1[i].size(1)))).view(1,-1) ],1))\n",
        "        else:\n",
        "            x1_p.append(Variable(x1[i]))\n",
        "        \n",
        "        if x2[i].size(1)<max_x2:\n",
        "            #v = Variable(LongTensor([x_to_ix['<PAD>']]*(max_x2-x2[i].size(1)))).view(1,-1)\n",
        "            #print(torch.cat((Variable(x2[i]), v), 1))\n",
        "            x2_p.append(torch.cat( [ Variable(x2[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x2-x2[i].size(1)))).view(1,-1) ],1))\n",
        "        else:\n",
        "            x2_p.append(Variable(x2[i]))\n",
        "        \n",
        "    x1_var = torch.cat(x1_p, 0)\n",
        "    x2_var = torch.cat(x2_p, 0)\n",
        "    target_var = Variable(LongTensor(y))\n",
        "    x1_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x1_var]\n",
        "    x2_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x2_var]\n",
        "    \n",
        "    return x1_var, x2_var, target_var, x1_len, x2_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wtnr6T6sSiSc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "batch = next(getBatch(BATCH_SIZE,train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEuyk5eOWEuS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pbatch = pad_to_batch(batch,source2index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V2LfurtTRj71",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1ea0324a-afa1-410a-ede4-44c49fa5ed39",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526261506153,
          "user_tz": 240,
          "elapsed": 425,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pbatch[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "   29   344   289  ...   1341   605  1698\n",
              "  866  1634    98  ...    106  1321     0\n",
              " 1398  1179    98  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              " 1554  1184   482  ...      0     0     0\n",
              "  413  1184   740  ...      0     0     0\n",
              "  413  1184   703  ...      0     0     0\n",
              "[torch.cuda.LongTensor of size 64x29 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "tgDAdycqrZBl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EncoderV(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size,hidden_size, n_layers=1,bidirec=False):\n",
        "        super(EncoderV, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        \n",
        "        if bidirec:\n",
        "            self.n_direction = 2 \n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
        "        else:\n",
        "            self.n_direction = 1\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
        "    \n",
        "    def init_hidden(self,inputs):  # input.size(0) = batch_size\n",
        "        hidden = Variable(torch.zeros(self.n_layers*self.n_direction,inputs.size(0),self.hidden_size))\n",
        "        return hidden.cuda() if USE_CUDA else hidden\n",
        "    \n",
        "    def init_weight(self):\n",
        "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
        "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
        "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
        "    \n",
        "    def forward(self, x, x_len):\n",
        "        \"\"\"\n",
        "        sequence -> sort -> pad and pack ->process using RNN -> unpack ->unsort\n",
        "\n",
        "        :param x: Variable\n",
        "        :param x_len: numpy list\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        \n",
        "        hidden = self.init_hidden(x)\n",
        "        \n",
        "        \"\"\"sort\"\"\"\n",
        "        x_sort_idx = np.argsort(x_len)[::-1]\n",
        "        x_unsort_idx = LongTensor(np.argsort(x_sort_idx))\n",
        "        x_len = np.array(x_len)[x_sort_idx]\n",
        "        x = x[LongTensor(x_sort_idx.copy())]\n",
        "      \n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        \"\"\"pack\"\"\"\n",
        "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True)\n",
        "                \n",
        "        \"\"\"process using RNN\"\"\"\n",
        "        out_pack, ht = self.gru(x_emb_p, hidden)\n",
        "        \n",
        "        \"\"\"unsort: h\"\"\"\n",
        "        ht = torch.transpose(ht, 0, 1)[\n",
        "            x_unsort_idx]  # (num_layers * num_directions, batch, hidden_size) -> (batch, ...)\n",
        "        ht = torch.transpose(ht, 0, 1)\n",
        "\n",
        "        #print(\"ht\", ht.shape)\n",
        "        if self.n_layers>1:\n",
        "            if self.n_direction==2:\n",
        "                ht = ht[-2:]\n",
        "                return out_pack, torch.cat((ht[0], ht[1]),1)\n",
        "            else:\n",
        "                ht = ht[-1]\n",
        "                return out_pack, ht\n",
        "\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQucPtqErioh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder1, encoder2, hidden_size):\n",
        "        \n",
        "        super(Model, self).__init__()\n",
        "        self.encoder1 = encoder1\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_size*4, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, 2)\n",
        "        \n",
        "    def init_weight(self):\n",
        "        \n",
        "        self.encoder1.init_weight()\n",
        "        #self.fc1.weight = nn.init.xavier_uniform(self.fc1.weight)\n",
        "        #self.fc2.weight = nn.init.xavier_uniform(self.fc2.weight)\n",
        "        \n",
        "    def forward(self, sen1, sen2, sen1_lengths, sen2_lengths):\n",
        "             \n",
        "        outputs_1, hidden_c1 = encoder1(sen1,sen1_lengths)\n",
        "        outputs_2, hidden_c2 = encoder1(sen2,sen2_lengths)\n",
        "        \n",
        "        hidden = torch.cat((hidden_c1, hidden_c2), 1).squeeze(1)  # batch * 2hidden\n",
        "        out = self.fc1(hidden)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQkE4gfMrlur",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "encoder1 = EncoderV(len(source2index),EMBEDDING_SIZE,HIDDEN_SIZE,2,True)\n",
        "if USE_CUDA:\n",
        "    encoder1 = encoder1.cuda()\n",
        "    \n",
        "model = Model(encoder1, encoder1, HIDDEN_SIZE)\n",
        "model.init_weight()\n",
        "\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=LR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmBOOTPhxVTF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6633f8b4-f501-4954-bcc3-ccf8e9a3cdd4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526260787091,
          "user_tz": 240,
          "elapsed": 517,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Model(\n",
              "  (encoder1): EncoderV(\n",
              "    (embedding): Embedding(1720, 128)\n",
              "    (gru): GRU(128, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1024, out_features=256)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=256, out_features=2)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "x08j3uuj4Igt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i,p in enumerate(model.parameters()):\n",
        "    if p.requires_grad:\n",
        "        print(i, \":\", p.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mVbrE_la4KNC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5d433edd-7259-4df6-e729-bc8311a03bc8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526260795000,
          "user_tz": 240,
          "elapsed": 414,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list(model.parameters())[17]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "-2.4837e-02 -3.9009e-03  5.5835e-03  ...  -1.4489e-02 -2.0116e-02  1.9349e-02\n",
              " 5.9822e-03 -5.6138e-04  2.2489e-02  ...   1.2735e-02 -1.2461e-03 -1.8798e-02\n",
              "-2.1907e-02 -1.5935e-02  2.3978e-02  ...   5.8109e-03 -3.6775e-03 -1.6479e-02\n",
              "                ...                   ⋱                   ...                \n",
              "-1.4632e-02 -3.1242e-02  2.4850e-02  ...   1.4655e-02  2.0924e-02  4.6784e-03\n",
              " 3.0224e-02  1.5460e-02 -2.3572e-02  ...   1.2580e-02  1.5037e-02  2.8139e-03\n",
              "-2.1273e-02 -9.3140e-03 -1.7181e-02  ...   2.2980e-02  2.7514e-02  2.6040e-02\n",
              "[torch.cuda.FloatTensor of size 256x1024 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "cXoRlKFZ4i4H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "02b64806-559c-4021-b975-08f37edc0f28",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526260797361,
          "user_tz": 240,
          "elapsed": 423,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list(model.parameters())[5]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              " 5.0677e-02 -4.0495e-03 -1.5734e-02  ...   6.1833e-02  1.9878e-03  3.9480e-02\n",
              "-6.0898e-02  4.5098e-02 -4.0118e-02  ...  -5.6398e-02 -2.4148e-02  7.2464e-03\n",
              "-4.6499e-02  5.7653e-02  3.6538e-02  ...   1.7100e-02 -5.4041e-03 -3.7763e-02\n",
              "                ...                   ⋱                   ...                \n",
              " 5.4879e-03  5.3690e-02  5.9184e-02  ...   2.5614e-02  5.1558e-03  1.0438e-03\n",
              "-6.1255e-03  6.0199e-03  2.8708e-02  ...  -4.9139e-02  2.0534e-02 -5.2865e-02\n",
              "-3.3467e-02 -8.7433e-03  1.7369e-02  ...   5.8226e-02  2.8482e-02  1.7205e-02\n",
              "[torch.cuda.FloatTensor of size 768x128 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "7u1jwcR6rv8D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "95ccb9a8-4b59-461d-867d-c75d324100fe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526260800362,
          "user_tz": 240,
          "elapsed": 901,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### test \n",
        "for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
        "    \n",
        "    # sen1 = batch * l\n",
        "    sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
        "    print(\"sen1 size: \", sen1.shape)\n",
        "    #input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in sen1]).view(sen1.size(0),-1)\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward + Backward + Optimize\n",
        "    outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "    print('outputs', outputs.size())\n",
        "    print('targets', targets.size())\n",
        "    loss = criterion(outputs, targets)\n",
        "    print('loss', loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    break"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sen1 size:  torch.Size([64, 44])\n",
            "outputs torch.Size([64, 2])\n",
            "targets torch.Size([64])\n",
            "loss Variable containing:\n",
            " 0.7057\n",
            "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EYyrQx1qsZUl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 4811
        },
        "outputId": "8945084f-f84f-4898-e689-c5512e0f8768"
      },
      "cell_type": "code",
      "source": [
        "total_step = round(len(train_data) / BATCH_SIZE)\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    \n",
        "    total_loss = []\n",
        "    \n",
        "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
        "        sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss.append(loss.data[0])\n",
        "\n",
        "        if (i+1) % 20 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                       .format(epoch+1, EPOCH, i+1, total_step, loss.data[0]))\n",
        "     \n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, EPOCH, np.mean(total_loss)))\n",
        "    \n",
        "    if RESCHEDULED == False and epoch  == EPOCH//2:\n",
        "        LR *= 0.01\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "        RESCHEDULED = True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [20/469], Loss: 0.4953\n",
            "Epoch [1/50], Step [40/469], Loss: 0.5467\n",
            "Epoch [1/50], Step [60/469], Loss: 0.5816\n",
            "Epoch [1/50], Step [80/469], Loss: 0.5139\n",
            "Epoch [1/50], Step [100/469], Loss: 0.5113\n",
            "Epoch [1/50], Step [120/469], Loss: 0.5806\n",
            "Epoch [1/50], Step [140/469], Loss: 0.4849\n",
            "Epoch [1/50], Step [160/469], Loss: 0.5790\n",
            "Epoch [1/50], Step [180/469], Loss: 0.5041\n",
            "Epoch [1/50], Step [200/469], Loss: 0.5422\n",
            "Epoch [1/50], Step [220/469], Loss: 0.5795\n",
            "Epoch [1/50], Step [240/469], Loss: 0.4388\n",
            "Epoch [1/50], Step [260/469], Loss: 0.5791\n",
            "Epoch [1/50], Step [280/469], Loss: 0.5041\n",
            "Epoch [1/50], Step [300/469], Loss: 0.4556\n",
            "Epoch [1/50], Step [320/469], Loss: 0.5174\n",
            "Epoch [1/50], Step [340/469], Loss: 0.3957\n",
            "Epoch [1/50], Step [360/469], Loss: 0.5238\n",
            "Epoch [1/50], Step [380/469], Loss: 0.5586\n",
            "Epoch [1/50], Step [400/469], Loss: 0.5081\n",
            "Epoch [1/50], Step [420/469], Loss: 0.4482\n",
            "Epoch [1/50], Step [440/469], Loss: 0.5306\n",
            "Epoch [1/50], Step [460/469], Loss: 0.5627\n",
            "Epoch [1/50], Loss: 0.5413\n",
            "Epoch [2/50], Step [20/469], Loss: 0.5447\n",
            "Epoch [2/50], Step [40/469], Loss: 0.4453\n",
            "Epoch [2/50], Step [60/469], Loss: 0.4832\n",
            "Epoch [2/50], Step [80/469], Loss: 0.4414\n",
            "Epoch [2/50], Step [100/469], Loss: 0.4683\n",
            "Epoch [2/50], Step [120/469], Loss: 0.5080\n",
            "Epoch [2/50], Step [140/469], Loss: 0.5445\n",
            "Epoch [2/50], Step [160/469], Loss: 0.5068\n",
            "Epoch [2/50], Step [180/469], Loss: 0.4446\n",
            "Epoch [2/50], Step [200/469], Loss: 0.3480\n",
            "Epoch [2/50], Step [220/469], Loss: 0.5255\n",
            "Epoch [2/50], Step [240/469], Loss: 0.4859\n",
            "Epoch [2/50], Step [260/469], Loss: 0.4644\n",
            "Epoch [2/50], Step [280/469], Loss: 0.5666\n",
            "Epoch [2/50], Step [300/469], Loss: 0.5654\n",
            "Epoch [2/50], Step [320/469], Loss: 0.3842\n",
            "Epoch [2/50], Step [340/469], Loss: 0.4622\n",
            "Epoch [2/50], Step [360/469], Loss: 0.5049\n",
            "Epoch [2/50], Step [380/469], Loss: 0.4618\n",
            "Epoch [2/50], Step [400/469], Loss: 0.5451\n",
            "Epoch [2/50], Step [420/469], Loss: 0.4657\n",
            "Epoch [2/50], Step [440/469], Loss: 0.5048\n",
            "Epoch [2/50], Step [460/469], Loss: 0.4841\n",
            "Epoch [2/50], Loss: 0.5281\n",
            "Epoch [3/50], Step [20/469], Loss: 0.6245\n",
            "Epoch [3/50], Step [40/469], Loss: 0.4661\n",
            "Epoch [3/50], Step [60/469], Loss: 0.4876\n",
            "Epoch [3/50], Step [80/469], Loss: 0.5456\n",
            "Epoch [3/50], Step [100/469], Loss: 0.6397\n",
            "Epoch [3/50], Step [120/469], Loss: 0.5445\n",
            "Epoch [3/50], Step [140/469], Loss: 0.5647\n",
            "Epoch [3/50], Step [160/469], Loss: 0.5877\n",
            "Epoch [3/50], Step [180/469], Loss: 0.4449\n",
            "Epoch [3/50], Step [200/469], Loss: 0.5070\n",
            "Epoch [3/50], Step [220/469], Loss: 0.6009\n",
            "Epoch [3/50], Step [240/469], Loss: 0.5253\n",
            "Epoch [3/50], Step [260/469], Loss: 0.5254\n",
            "Epoch [3/50], Step [280/469], Loss: 0.4858\n",
            "Epoch [3/50], Step [300/469], Loss: 0.4831\n",
            "Epoch [3/50], Step [320/469], Loss: 0.5907\n",
            "Epoch [3/50], Step [340/469], Loss: 0.5870\n",
            "Epoch [3/50], Step [360/469], Loss: 0.5065\n",
            "Epoch [3/50], Step [380/469], Loss: 0.6813\n",
            "Epoch [3/50], Step [400/469], Loss: 0.5884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [3/50], Step [420/469], Loss: 0.5253\n",
            "Epoch [3/50], Step [440/469], Loss: 0.5645\n",
            "Epoch [3/50], Step [460/469], Loss: 0.3679\n",
            "Epoch [3/50], Loss: 0.5240\n",
            "Epoch [4/50], Step [20/469], Loss: 0.5254\n",
            "Epoch [4/50], Step [40/469], Loss: 0.5050\n",
            "Epoch [4/50], Step [60/469], Loss: 0.4858\n",
            "Epoch [4/50], Step [80/469], Loss: 0.5848\n",
            "Epoch [4/50], Step [100/469], Loss: 0.4139\n",
            "Epoch [4/50], Step [120/469], Loss: 0.5449\n",
            "Epoch [4/50], Step [140/469], Loss: 0.5642\n",
            "Epoch [4/50], Step [160/469], Loss: 0.6197\n",
            "Epoch [4/50], Step [180/469], Loss: 0.5456\n",
            "Epoch [4/50], Step [200/469], Loss: 0.4408\n",
            "Epoch [4/50], Step [220/469], Loss: 0.5903\n",
            "Epoch [4/50], Step [240/469], Loss: 0.5056\n",
            "Epoch [4/50], Step [260/469], Loss: 0.5447\n",
            "Epoch [4/50], Step [280/469], Loss: 0.6448\n",
            "Epoch [4/50], Step [300/469], Loss: 0.4839\n",
            "Epoch [4/50], Step [320/469], Loss: 0.5054\n",
            "Epoch [4/50], Step [340/469], Loss: 0.4640\n",
            "Epoch [4/50], Step [360/469], Loss: 0.5055\n",
            "Epoch [4/50], Step [380/469], Loss: 0.5448\n",
            "Epoch [4/50], Step [400/469], Loss: 0.5823\n",
            "Epoch [4/50], Step [420/469], Loss: 0.5253\n",
            "Epoch [4/50], Step [440/469], Loss: 0.5048\n",
            "Epoch [4/50], Step [460/469], Loss: 0.5665\n",
            "Epoch [4/50], Loss: 0.5241\n",
            "Epoch [5/50], Step [20/469], Loss: 0.4836\n",
            "Epoch [5/50], Step [40/469], Loss: 0.6675\n",
            "Epoch [5/50], Step [60/469], Loss: 0.5852\n",
            "Epoch [5/50], Step [80/469], Loss: 0.4458\n",
            "Epoch [5/50], Step [100/469], Loss: 0.5083\n",
            "Epoch [5/50], Step [120/469], Loss: 0.6410\n",
            "Epoch [5/50], Step [140/469], Loss: 0.5638\n",
            "Epoch [5/50], Step [160/469], Loss: 0.5254\n",
            "Epoch [5/50], Step [180/469], Loss: 0.6571\n",
            "Epoch [5/50], Step [200/469], Loss: 0.4849\n",
            "Epoch [5/50], Step [220/469], Loss: 0.4253\n",
            "Epoch [5/50], Step [240/469], Loss: 0.6648\n",
            "Epoch [5/50], Step [260/469], Loss: 0.5640\n",
            "Epoch [5/50], Step [280/469], Loss: 0.4843\n",
            "Epoch [5/50], Step [300/469], Loss: 0.4197\n",
            "Epoch [5/50], Step [320/469], Loss: 0.4831\n",
            "Epoch [5/50], Step [340/469], Loss: 0.5054\n",
            "Epoch [5/50], Step [360/469], Loss: 0.5455\n",
            "Epoch [5/50], Step [380/469], Loss: 0.6249\n",
            "Epoch [5/50], Step [400/469], Loss: 0.6010\n",
            "Epoch [5/50], Step [420/469], Loss: 0.5456\n",
            "Epoch [5/50], Step [440/469], Loss: 0.4650\n",
            "Epoch [5/50], Step [460/469], Loss: 0.4851\n",
            "Epoch [5/50], Loss: 0.5241\n",
            "Epoch [6/50], Step [20/469], Loss: 0.4849\n",
            "Epoch [6/50], Step [40/469], Loss: 0.5867\n",
            "Epoch [6/50], Step [60/469], Loss: 0.5254\n",
            "Epoch [6/50], Step [80/469], Loss: 0.5253\n",
            "Epoch [6/50], Step [100/469], Loss: 0.6368\n",
            "Epoch [6/50], Step [120/469], Loss: 0.4445\n",
            "Epoch [6/50], Step [140/469], Loss: 0.5647\n",
            "Epoch [6/50], Step [160/469], Loss: 0.6219\n",
            "Epoch [6/50], Step [180/469], Loss: 0.5636\n",
            "Epoch [6/50], Step [200/469], Loss: 0.4491\n",
            "Epoch [6/50], Step [220/469], Loss: 0.7193\n",
            "Epoch [6/50], Step [240/469], Loss: 0.6043\n",
            "Epoch [6/50], Step [260/469], Loss: 0.5451\n",
            "Epoch [6/50], Step [280/469], Loss: 0.5671\n",
            "Epoch [6/50], Step [300/469], Loss: 0.5894\n",
            "Epoch [6/50], Step [320/469], Loss: 0.6043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [6/50], Step [340/469], Loss: 0.5254\n",
            "Epoch [6/50], Step [360/469], Loss: 0.6308\n",
            "Epoch [6/50], Step [380/469], Loss: 0.5254\n",
            "Epoch [6/50], Step [400/469], Loss: 0.4864\n",
            "Epoch [6/50], Step [420/469], Loss: 0.5054\n",
            "Epoch [6/50], Step [440/469], Loss: 0.7060\n",
            "Epoch [6/50], Step [460/469], Loss: 0.4854\n",
            "Epoch [6/50], Loss: 0.5241\n",
            "Epoch [7/50], Step [20/469], Loss: 0.5450\n",
            "Epoch [7/50], Step [40/469], Loss: 0.4660\n",
            "Epoch [7/50], Step [60/469], Loss: 0.4483\n",
            "Epoch [7/50], Step [80/469], Loss: 0.5462\n",
            "Epoch [7/50], Step [100/469], Loss: 0.4226\n",
            "Epoch [7/50], Step [120/469], Loss: 0.5254\n",
            "Epoch [7/50], Step [140/469], Loss: 0.5048\n",
            "Epoch [7/50], Step [160/469], Loss: 0.5051\n",
            "Epoch [7/50], Step [180/469], Loss: 0.6773\n",
            "Epoch [7/50], Step [200/469], Loss: 0.4853\n",
            "Epoch [7/50], Step [220/469], Loss: 0.5452\n",
            "Epoch [7/50], Step [240/469], Loss: 0.4839\n",
            "Epoch [7/50], Step [260/469], Loss: 0.5065\n",
            "Epoch [7/50], Step [280/469], Loss: 0.5267\n",
            "Epoch [7/50], Step [300/469], Loss: 0.5260\n",
            "Epoch [7/50], Step [320/469], Loss: 0.4233\n",
            "Epoch [7/50], Step [340/469], Loss: 0.5832\n",
            "Epoch [7/50], Step [360/469], Loss: 0.6054\n",
            "Epoch [7/50], Step [380/469], Loss: 0.5679\n",
            "Epoch [7/50], Step [400/469], Loss: 0.5465\n",
            "Epoch [7/50], Step [420/469], Loss: 0.5462\n",
            "Epoch [7/50], Step [440/469], Loss: 0.6070\n",
            "Epoch [7/50], Step [460/469], Loss: 0.4873\n",
            "Epoch [7/50], Loss: 0.5242\n",
            "Epoch [8/50], Step [20/469], Loss: 0.5253\n",
            "Epoch [8/50], Step [40/469], Loss: 0.5651\n",
            "Epoch [8/50], Step [60/469], Loss: 0.6447\n",
            "Epoch [8/50], Step [80/469], Loss: 0.5454\n",
            "Epoch [8/50], Step [100/469], Loss: 0.4410\n",
            "Epoch [8/50], Step [120/469], Loss: 0.4651\n",
            "Epoch [8/50], Step [140/469], Loss: 0.6258\n",
            "Epoch [8/50], Step [160/469], Loss: 0.5630\n",
            "Epoch [8/50], Step [180/469], Loss: 0.5059\n",
            "Epoch [8/50], Step [200/469], Loss: 0.3462\n",
            "Epoch [8/50], Step [220/469], Loss: 0.4826\n",
            "Epoch [8/50], Step [240/469], Loss: 0.6279\n",
            "Epoch [8/50], Step [260/469], Loss: 0.6195\n",
            "Epoch [8/50], Step [280/469], Loss: 0.5057\n",
            "Epoch [8/50], Step [300/469], Loss: 0.6084\n",
            "Epoch [8/50], Step [320/469], Loss: 0.5844\n",
            "Epoch [8/50], Step [340/469], Loss: 0.4250\n",
            "Epoch [8/50], Step [360/469], Loss: 0.5664\n",
            "Epoch [8/50], Step [380/469], Loss: 0.6248\n",
            "Epoch [8/50], Step [400/469], Loss: 0.5642\n",
            "Epoch [8/50], Step [420/469], Loss: 0.6282\n",
            "Epoch [8/50], Step [440/469], Loss: 0.5060\n",
            "Epoch [8/50], Step [460/469], Loss: 0.5056\n",
            "Epoch [8/50], Loss: 0.5243\n",
            "Epoch [9/50], Step [20/469], Loss: 0.6039\n",
            "Epoch [9/50], Step [40/469], Loss: 0.5869\n",
            "Epoch [9/50], Step [60/469], Loss: 0.6125\n",
            "Epoch [9/50], Step [80/469], Loss: 0.5667\n",
            "Epoch [9/50], Step [100/469], Loss: 0.4849\n",
            "Epoch [9/50], Step [120/469], Loss: 0.4849\n",
            "Epoch [9/50], Step [140/469], Loss: 0.5065\n",
            "Epoch [9/50], Step [160/469], Loss: 0.6422\n",
            "Epoch [9/50], Step [180/469], Loss: 0.5253\n",
            "Epoch [9/50], Step [200/469], Loss: 0.6085\n",
            "Epoch [9/50], Step [220/469], Loss: 0.4426\n",
            "Epoch [9/50], Step [240/469], Loss: 0.5450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [9/50], Step [260/469], Loss: 0.5624\n",
            "Epoch [9/50], Step [280/469], Loss: 0.5254\n",
            "Epoch [9/50], Step [300/469], Loss: 0.5456\n",
            "Epoch [9/50], Step [320/469], Loss: 0.6065\n",
            "Epoch [9/50], Step [340/469], Loss: 0.5048\n",
            "Epoch [9/50], Step [360/469], Loss: 0.4214\n",
            "Epoch [9/50], Step [380/469], Loss: 0.5668\n",
            "Epoch [9/50], Step [400/469], Loss: 0.4669\n",
            "Epoch [9/50], Step [420/469], Loss: 0.5655\n",
            "Epoch [9/50], Step [440/469], Loss: 0.6063\n",
            "Epoch [9/50], Step [460/469], Loss: 0.5655\n",
            "Epoch [9/50], Loss: 0.5239\n",
            "Epoch [10/50], Step [20/469], Loss: 0.7125\n",
            "Epoch [10/50], Step [40/469], Loss: 0.5459\n",
            "Epoch [10/50], Step [60/469], Loss: 0.5454\n",
            "Epoch [10/50], Step [80/469], Loss: 0.5630\n",
            "Epoch [10/50], Step [100/469], Loss: 0.4883\n",
            "Epoch [10/50], Step [120/469], Loss: 0.4523\n",
            "Epoch [10/50], Step [140/469], Loss: 0.6947\n",
            "Epoch [10/50], Step [160/469], Loss: 0.5650\n",
            "Epoch [10/50], Step [180/469], Loss: 0.4846\n",
            "Epoch [10/50], Step [200/469], Loss: 0.4842\n",
            "Epoch [10/50], Step [220/469], Loss: 0.4442\n",
            "Epoch [10/50], Step [240/469], Loss: 0.6063\n",
            "Epoch [10/50], Step [260/469], Loss: 0.5652\n",
            "Epoch [10/50], Step [280/469], Loss: 0.5254\n",
            "Epoch [10/50], Step [300/469], Loss: 0.5048\n",
            "Epoch [10/50], Step [320/469], Loss: 0.5050\n",
            "Epoch [10/50], Step [340/469], Loss: 0.4057\n",
            "Epoch [10/50], Step [360/469], Loss: 0.5672\n",
            "Epoch [10/50], Step [380/469], Loss: 0.5055\n",
            "Epoch [10/50], Step [400/469], Loss: 0.5642\n",
            "Epoch [10/50], Step [420/469], Loss: 0.4869\n",
            "Epoch [10/50], Step [440/469], Loss: 0.4302\n",
            "Epoch [10/50], Step [460/469], Loss: 0.6257\n",
            "Epoch [10/50], Loss: 0.5240\n",
            "Epoch [11/50], Step [20/469], Loss: 0.6087\n",
            "Epoch [11/50], Step [40/469], Loss: 0.4260\n",
            "Epoch [11/50], Step [60/469], Loss: 0.6882\n",
            "Epoch [11/50], Step [80/469], Loss: 0.5049\n",
            "Epoch [11/50], Step [100/469], Loss: 0.4256\n",
            "Epoch [11/50], Step [120/469], Loss: 0.4847\n",
            "Epoch [11/50], Step [140/469], Loss: 0.6637\n",
            "Epoch [11/50], Step [160/469], Loss: 0.4859\n",
            "Epoch [11/50], Step [180/469], Loss: 0.4856\n",
            "Epoch [11/50], Step [200/469], Loss: 0.6113\n",
            "Epoch [11/50], Step [220/469], Loss: 0.5452\n",
            "Epoch [11/50], Step [240/469], Loss: 0.6038\n",
            "Epoch [11/50], Step [260/469], Loss: 0.5253\n",
            "Epoch [11/50], Step [280/469], Loss: 0.5254\n",
            "Epoch [11/50], Step [300/469], Loss: 0.6052\n",
            "Epoch [11/50], Step [320/469], Loss: 0.4859\n",
            "Epoch [11/50], Step [340/469], Loss: 0.5841\n",
            "Epoch [11/50], Step [360/469], Loss: 0.5080\n",
            "Epoch [11/50], Step [380/469], Loss: 0.4454\n",
            "Epoch [11/50], Step [400/469], Loss: 0.4446\n",
            "Epoch [11/50], Step [420/469], Loss: 0.4862\n",
            "Epoch [11/50], Step [440/469], Loss: 0.5048\n",
            "Epoch [11/50], Step [460/469], Loss: 0.5065\n",
            "Epoch [11/50], Loss: 0.5241\n",
            "Epoch [12/50], Step [20/469], Loss: 0.6067\n",
            "Epoch [12/50], Step [40/469], Loss: 0.5447\n",
            "Epoch [12/50], Step [60/469], Loss: 0.5052\n",
            "Epoch [12/50], Step [80/469], Loss: 0.5882\n",
            "Epoch [12/50], Step [100/469], Loss: 0.5677\n",
            "Epoch [12/50], Step [120/469], Loss: 0.6107\n",
            "Epoch [12/50], Step [140/469], Loss: 0.4061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [12/50], Step [160/469], Loss: 0.5647\n",
            "Epoch [12/50], Step [180/469], Loss: 0.5649\n",
            "Epoch [12/50], Step [200/469], Loss: 0.3844\n",
            "Epoch [12/50], Step [220/469], Loss: 0.5467\n",
            "Epoch [12/50], Step [240/469], Loss: 0.5447\n",
            "Epoch [12/50], Step [260/469], Loss: 0.5657\n",
            "Epoch [12/50], Step [280/469], Loss: 0.4668\n",
            "Epoch [12/50], Step [300/469], Loss: 0.5257\n",
            "Epoch [12/50], Step [320/469], Loss: 0.5446\n",
            "Epoch [12/50], Step [340/469], Loss: 0.5056\n",
            "Epoch [12/50], Step [360/469], Loss: 0.5253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RDPcrit3PT4X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def infer(sens):\n",
        "    \n",
        "    outputs = model(sens[0], sens[1], [sens[0].size(1)], [sens[1].size(1)])  \n",
        "    return np.argmax(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJgnhA-4QKlp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3971e37b-5cb1-42eb-8b6a-2f0e3be4cfc2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526262797050,
          "user_tz": 240,
          "elapsed": 409,
          "user": {
            "displayName": "Pengcheng Jia",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112854971302097969837"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#test = random.choice(train_data)\n",
        "#test = random.sample(train_data, 5)\n",
        "\n",
        "sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(test,source2index)\n",
        "outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
        "\n",
        "predict = np.array(np.argmax(outputs.data, 1))\n",
        "targets = np.array(targets.data)\n",
        "print(\"Predict:\", predict)\n",
        "print(\"Truth:\", targets)\n",
        "print(\"Correct: \", np.sum(predict == targets))\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict: [0 0 0 0 0]\n",
            "Truth: [0 1 0 0 0]\n",
            "Correct:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LoX2Ok3VXHxY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "print(\"confusion_matrix: \\n\" ,confusion_matrix(predict, targets)\n",
        "print(precision_score(predict, targets))\n",
        "print(recall_score(predict, targets))\n",
        "print(f1_score(predict, targets))\n",
        "\n",
        "## tn fp\n",
        "## fn tp"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}