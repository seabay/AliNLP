{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2DThheVCSE69"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1526498741652,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "QCxPUxjZseZN",
    "outputId": "cea1ce40-e36d-453e-a773-6108bc422da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cu80'"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zFLRFF99R6CK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import PackedSequence,pack_padded_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1526498742414,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "ar3EUnczNrjl",
    "outputId": "d0706e55-a9fd-44c4-91c2-6f2664ddcaf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113255790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0EQ1faqTTJTy"
   },
   "outputs": [],
   "source": [
    "# 安装 PyDrive 操作库，该操作每个 notebook 只需要执行一次\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 授权登录，仅第一次的时候会鉴权\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1526498745921,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "z0iYUJ9kTUxf",
    "outputId": "3b528ad5-a943-4258-e351-202867008f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: data, id: 16zfnt8Cnuznzwj2RHGrxvyfyA6iQPRXx, mimeType: application/vnd.google-apps.folder\n",
      "title: Colab Notebooks, id: 1DDn16_H4dL75WfkYDpWNxRzqJkH6uvsk, mimeType: application/vnd.google-apps.folder\n",
      "title: 02 - email-templates.png, id: 0BzICsNHMK-GFdnZhNFBoVXdobkhBa3h2eUtwbXY1ek15Sk53, mimeType: image/png\n",
      "title: ATEC-Alipay, id: 1UyfXNCoPHh73E4jO-pgombXQShfYkzAVgGfSUnU7OAE, mimeType: application/vnd.google-apps.document\n",
      "title: The Annotated _Attention is All You Need_.ipynb, id: 1zIkaTyyRtMY0qRTuUxe9J10xR3S9J5Xc, mimeType: application/vnd.google.colab\n",
      "title: Copy of mixture_of_softmaxes.ipynb, id: 1HiJvBimCdWvFP7SoLs9bWNR-JbCQSRsG, mimeType: application/vnd.google.colab\n",
      "title: Copy of Hello, Colaboratory, id: 0BzICsNHMK-GFcFBrQkV2UXpMVGM, mimeType: application/vnd.google.colab\n",
      "title: 2017 Calendar, id: 1jw6VChc9SGayYuK5Zmy2PjaiwWM0tzGFrPG9eatsSNw, mimeType: application/vnd.google-apps.spreadsheet\n",
      "title: Getting started, id: 0BzICsNHMK-GFc3RhcnRlcl9maWxlX2Rhc2hlclYw, mimeType: application/pdf\n"
     ]
    }
   ],
   "source": [
    "# 列出根目录的所有文件\n",
    "# \"q\" 查询条件教程详见：https://developers.google.com/drive/v2/web/search-parameters\n",
    "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list:\n",
    "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1526498746601,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "zPnkftXqUJOf",
    "outputId": "6e60741d-7dcc-44db-df12-871521ee98b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: atec_nlp_sim_train.csv, id: 1py3JAFOLOH2lM-lOqYyP_LfqaImlOqL_, mimeType: text/csv\n"
     ]
    }
   ],
   "source": [
    "# '目录 id' in parents\n",
    "file_list = drive.ListFile({'q': \"'16zfnt8Cnuznzwj2RHGrxvyfyA6iQPRXx' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list:\n",
    "  print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QE8YA5PwU1pV"
   },
   "outputs": [],
   "source": [
    "file = drive.CreateFile({'id': \"1py3JAFOLOH2lM-lOqYyP_LfqaImlOqL_\"}) \n",
    "#这里的下载操作只是缓存，不会在你的Google Drive 目录下多下载一个文件\n",
    "file.GetContentFile('data.csv', \"text/csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "--NHxEVRVEW_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', sep='\\t', names=['number', \"sen1\", \"sen2\", \"label\"], skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1526498748710,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "5mnBj_KKVKFW",
    "outputId": "95fd4729-1870-49df-e8b2-48878e06168d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>sen1</th>\n",
       "      <th>sen2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿怎么更改花呗手机号码</td>\n",
       "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number             sen1                            sen2  label\n",
       "0       1      ﻿怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号      1\n",
       "1       2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款      0"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "U31TBWmDFh4R"
   },
   "outputs": [],
   "source": [
    "MIN_LENGTH = 3\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N7rrWLo1SZbY"
   },
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    s = re.sub(r\"\\d+\", r\"N\", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1526498750606,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "oxcCgkzsVd6z",
    "outputId": "0f5e6866-6f09-4988-a14b-13d3810b3fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39346 39346 39346\n",
      "﻿怎么更改花呗手机号码 @@@@ 我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号 @@@@ 1\n",
      "CPU times: user 510 ms, sys: 1 ms, total: 511 ms\n",
      "Wall time: 515 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X1_r = list(map(normalize_string, df.sen1.tolist()))\n",
    "X2_r = list(map(normalize_string, df.sen2.tolist()))\n",
    "y_r = df.label.tolist()\n",
    "\n",
    "for sen1, sen2, y in zip(X1_r, X2_r, y_r):\n",
    "  if len(sen1) > MAX_LENGTH or len(sen2) > MAX_LENGTH:\n",
    "    X1_r.remove(sen1)\n",
    "    X2_r.remove(sen2)\n",
    "    y_r.remove(y)\n",
    "    \n",
    "    X1_r.append(sen1[:MAX_LENGTH])\n",
    "    X2_r.append(sen2[:MAX_LENGTH])\n",
    "    y_r.append(y)\n",
    "    \n",
    "print(len(X1_r), len(X2_r), len(y_r))\n",
    "print(X1_r[0], \"@@@@\", X2_r[0], \"@@@@\",y_r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1526498751090,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "b7oGud6MVi7x",
    "outputId": "53c0610f-9838-4e92-e462-c2220e600e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(flatten(X1_r + X2_r)))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cNQj-kWjVkFi"
   },
   "outputs": [],
   "source": [
    "source2index = {'<PAD>':0,'<UNK>':1,'<s>':2,'</s>':3}\n",
    "for vo in vocab:\n",
    "    if vo not in source2index.keys():\n",
    "        source2index[vo]=len(source2index)\n",
    "index2source = {v:k for k,v in source2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1526498751866,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "kW1vMMwZVnVS",
    "outputId": "947d2dd7-ecbe-4aaa-a87e-2147e35235c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2source[source2index[\"N\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BpXO_1YKV6HE"
   },
   "outputs": [],
   "source": [
    "EPOCH=150\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "LR = 0.01\n",
    "DECODER_LEARNING_RATIO=5.0\n",
    "RESCHEDULED=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Yfl0IVKNSNSG"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1526498753150,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "WU6658BRsl8I",
    "outputId": "f4f9f28c-632f-4f68-9b9b-f06e09d5eb2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1526498753584,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "Q_C1LkOa2Zru",
    "outputId": "bba41c39-e675-4829-8276-ceecc526aa51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.cuda.LongTensor"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UJHv0H-QWbyJ"
   },
   "outputs": [],
   "source": [
    "#alpha = Variable(torch.Tensor([0.7, 0.3]))\n",
    "alpha = Variable(FloatTensor([0.75, 0.25]))  # increase loss weights for positive samples\n",
    "gamma = 2\n",
    "\n",
    "def one_hot(index, classes):\n",
    "    size = index.size() + (classes,)\n",
    "    view = index.size() + (1,)\n",
    "\n",
    "    mask = FloatTensor(*size).fill_(0)\n",
    "    index = index.view(*view)\n",
    "    ones = 1.\n",
    "\n",
    "    if isinstance(index, Variable):\n",
    "        ones = Variable(FloatTensor(index.size()).fill_(1))\n",
    "        mask = Variable(mask, volatile=index.volatile)\n",
    "\n",
    "    return mask.scatter_(1, index, ones)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        y = one_hot(target, input.size(-1))\n",
    "        logit = F.softmax(input, dim=-1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)   # pt\n",
    "\n",
    "        loss = -1 * y * torch.log(logit) * alpha # cross entropy\n",
    "        loss = loss * (1 - logit) ** self.gamma # focal loss\n",
    "\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1VNP_OnfSZQM"
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5O-H4hidSV9R"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<unk>\"], seq))\n",
    "    return LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1526498763801,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "dfJO_v1nVp5t",
    "outputId": "2b42a72a-955c-4bb8-a73d-bda8683cddd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 s, sys: 1.29 s, total: 4.58 s\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X1_p, X2_p = [],[]\n",
    "ta_p = []\n",
    "\n",
    "for s1, s2, ta in zip(X1_r, X2_r, y_r):\n",
    "    X1_p.append(prepare_sequence(s1,source2index).view(1,-1))\n",
    "    X2_p.append(prepare_sequence(s2,source2index).view(1,-1))\n",
    "    ta_p.append(ta)\n",
    "    \n",
    "data = list(zip(X1_p, X2_p, ta_p))\n",
    "np.random.shuffle(data)\n",
    "train_data = data[:30000]\n",
    "validate_data = data[30000:35000]\n",
    "test_data = data[35000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1526498765142,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "B6w5k0yIqA2q",
    "outputId": "2de03abc-8d54-47a7-ab05-cb774abcffb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "   510   525   863   591   911   843   402  1637  1600  1032  1569\n",
       " [torch.cuda.LongTensor of size 1x11 (GPU 0)], \n",
       " \n",
       " Columns 0 to 12 \n",
       "    13  1544   843   432  1252   706   846   762  1210  1059  1013   988  1356\n",
       " \n",
       " Columns 13 to 23 \n",
       "   937   723  1399   331   510   525   377   988   937  1127   723\n",
       " [torch.cuda.LongTensor of size 1x24 (GPU 0)], 0)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wqhQUb2bSZmF"
   },
   "outputs": [],
   "source": [
    "def pad_to_batch(batch,x_to_ix):\n",
    "    \n",
    "    sorted_batch =  sorted(batch, key=lambda b:b[0].size(1),reverse=True) # sort by len\n",
    "    \n",
    "    x1, x2, y = list(zip(*sorted_batch))\n",
    "    max_x1 = max([s.size(1) for s in x1])\n",
    "    max_x2 = max([s.size(1) for s in x2])\n",
    "    \n",
    "    x1_p, x2_p, y_p = [],[],[]\n",
    "    for i in range(len(batch)):\n",
    "      \n",
    "        if x1[i].size(1)<max_x1:\n",
    "            x1_p.append(torch.cat( [ Variable(x1[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x1-x1[i].size(1)))).view(1,-1) ],1))\n",
    "        else:\n",
    "            x1_p.append(Variable(x1[i]))\n",
    "        \n",
    "        if x2[i].size(1)<max_x2:\n",
    "            x2_p.append(torch.cat( [ Variable(x2[i]),Variable(LongTensor([x_to_ix['<PAD>']]*(max_x2-x2[i].size(1)))).view(1,-1) ],1))\n",
    "        else:\n",
    "            x2_p.append(Variable(x2[i]))\n",
    "        \n",
    "    x1_var = torch.cat(x1_p, 0)\n",
    "    x2_var = torch.cat(x2_p, 0)\n",
    "    target_var = Variable(LongTensor(y))\n",
    "    x1_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x1_var]\n",
    "    x2_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in x2_var]\n",
    "    \n",
    "    return x1_var, x2_var, target_var, x1_len, x2_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wtnr6T6sSiSc"
   },
   "outputs": [],
   "source": [
    "batch = next(getBatch(BATCH_SIZE,train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HEuyk5eOWEuS"
   },
   "outputs": [],
   "source": [
    "pbatch = pad_to_batch(batch,source2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1526498770727,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "V2LfurtTRj71",
    "outputId": "991feec8-1687-4a80-c274-997c5cf14a21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  988  1009   324  ...     17   434   666\n",
       "  402  1637  1041  ...      0     0     0\n",
       "  268   610   436  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       " 1588   525   723  ...      0     0     0\n",
       " 1127   723   510  ...      0     0     0\n",
       "  219    60  1588  ...      0     0     0\n",
       "[torch.cuda.LongTensor of size 128x40 (GPU 0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbatch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0uX8z0b3FZXi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_perf():\n",
    "  \n",
    "  print(\"========== performance on randomly selected 5000 samples from training data\")\n",
    "  samples = random.sample(train_data, 5000)\n",
    "  sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(samples,source2index)\n",
    "  outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
    "  t_predict = np.array(np.argmax(outputs.data, 1))\n",
    "  t_targets = np.array(targets.data)\n",
    "  print(\"Correct: \", np.sum(t_targets == t_predict))\n",
    "  print(\"tn, fp, fn, tp \\n\", confusion_matrix(t_targets, t_predict).ravel())\n",
    "  print(\"precsion: \", precision_score(t_predict, t_targets))\n",
    "  print(\"recall: \", recall_score(t_predict, t_targets))\n",
    "  print(\"f1 score: \", f1_score(t_predict, t_targets))\n",
    "  \n",
    "def validate_perf():\n",
    "  \n",
    "  print(\"========== performance on validation data\")\n",
    "  sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(validate_data,source2index)\n",
    "  outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
    "  predict = np.array(np.argmax(outputs.data, 1))\n",
    "  targets = np.array(targets.data)\n",
    "  print(\"Correct: \", np.sum(predict == targets))\n",
    "  print(\"tn, fp, fn, tp \\n\", confusion_matrix(targets, predict).ravel())\n",
    "  print(\"precsion: \", precision_score(predict, targets))\n",
    "  print(\"recall: \", recall_score(predict, targets))\n",
    "  print(\"f1 score: \", f1_score(predict, targets))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1526498784179,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "1OC25Ok0ql2I",
    "outputId": "f6b3d3b9-a668-4143-f33a-a2a608aa3f93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([i[2] for i in validate_data]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1526498785875,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "WASmUfVqtaRH",
    "outputId": "f5132152-56a5-4034-909d-8cf938ff6015"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3973"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([i[2] for i in validate_data]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tgDAdycqrZBl"
   },
   "outputs": [],
   "source": [
    "class EncoderV(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size,hidden_size, n_layers=1,bidirec=False):\n",
    "        super(EncoderV, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        \n",
    "        if bidirec:\n",
    "            self.n_direction = 2 \n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
    "        else:\n",
    "            self.n_direction = 1\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "    \n",
    "    def init_hidden(self,inputs):  # input.size(0) = batch_size\n",
    "        hidden = Variable(torch.zeros(self.n_layers*self.n_direction,inputs.size(0),self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "    \n",
    "    def forward(self, x, x_len):\n",
    "        \"\"\"\n",
    "        sequence -> sort -> pad and pack ->process using RNN -> unpack ->unsort\n",
    "\n",
    "        :param x: Variable\n",
    "        :param x_len: numpy list\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = self.init_hidden(x)      #### initialise starting state\n",
    "        \n",
    "        \"\"\"sort\"\"\"\n",
    "        x_sort_idx = np.argsort(x_len)[::-1]\n",
    "        x_unsort_idx = LongTensor(np.argsort(x_sort_idx))\n",
    "        x_len = np.array(x_len)[x_sort_idx]\n",
    "        x = x[LongTensor(x_sort_idx.copy())]\n",
    "      \n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.drop(embedded)\n",
    "        \n",
    "        \"\"\"pack\"\"\"\n",
    "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True)\n",
    "                \n",
    "        \"\"\"process using RNN\"\"\"\n",
    "        out_pack, ht = self.gru(x_emb_p, hidden)\n",
    "        \n",
    "        \"\"\"unsort: h\"\"\"\n",
    "        ht = torch.transpose(ht, 0, 1)[\n",
    "            x_unsort_idx]  # (num_layers * num_directions, batch, hidden_size) -> (batch, ...)\n",
    "        ht = torch.transpose(ht, 0, 1)\n",
    "\n",
    "        #print(\"ht\", ht.shape)\n",
    "        if self.n_layers>1:\n",
    "            if self.n_direction==2:\n",
    "                ht = ht[-2:]\n",
    "                return out_pack, torch.cat((ht[0], ht[1]),1)\n",
    "            else:\n",
    "                ht = ht[-1]\n",
    "                return out_pack, ht\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iQucPtqErioh"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder1, encoder2, hidden_size):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.encoder1 = encoder1\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.relu = nn. ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def init_weight(self):\n",
    "        \n",
    "        self.encoder1.init_weight()\n",
    "        #self.fc1.weight = nn.init.xavier_uniform(self.fc1.weight)\n",
    "        #self.fc2.weight = nn.init.xavier_uniform(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, sen1, sen2, sen1_lengths, sen2_lengths):\n",
    "             \n",
    "        outputs_1, hidden_c1 = encoder1(sen1,sen1_lengths)\n",
    "        outputs_2, hidden_c2 = encoder1(sen2,sen2_lengths)\n",
    "        \n",
    "        hidden_c1 = self.drop(hidden_c1)\n",
    "        hidden_c2 = self.drop(hidden_c2)\n",
    "        hidden = torch.cat((hidden_c1, hidden_c2), 1).squeeze(1)  # batch * 2hidden\n",
    "        #hidden = self.drop(hidden)\n",
    "        out = self.fc1(hidden)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nQkE4gfMrlur"
   },
   "outputs": [],
   "source": [
    "encoder1 = EncoderV(len(source2index),EMBEDDING_SIZE,HIDDEN_SIZE,2,True)\n",
    "model = Model(encoder1, encoder1, HIDDEN_SIZE)\n",
    "model.init_weight()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = FocalLoss(2)\n",
    "criterion = FocalLoss(2)\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1526498793825,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "vmBOOTPhxVTF",
    "outputId": "c6ac3aaa-72c6-4709-8225-ab3cfcdbc126"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (encoder1): EncoderV(\n",
       "    (embedding): Embedding(1705, 128)\n",
       "    (drop): Dropout(p=0.1)\n",
       "    (gru): GRU(128, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (drop): Dropout(p=0.1)\n",
       "  (fc1): Linear(in_features=1024, out_features=256)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=2)\n",
       ")>"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1526498795511,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "x08j3uuj4Igt",
    "outputId": "a526e112-ce51-4aa4-ee9e-8a2a2e8ec15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : torch.Size([1705, 128])\n",
      "1 : torch.Size([768, 128])\n",
      "2 : torch.Size([768, 256])\n",
      "3 : torch.Size([768])\n",
      "4 : torch.Size([768])\n",
      "5 : torch.Size([768, 128])\n",
      "6 : torch.Size([768, 256])\n",
      "7 : torch.Size([768])\n",
      "8 : torch.Size([768])\n",
      "9 : torch.Size([768, 512])\n",
      "10 : torch.Size([768, 256])\n",
      "11 : torch.Size([768])\n",
      "12 : torch.Size([768])\n",
      "13 : torch.Size([768, 512])\n",
      "14 : torch.Size([768, 256])\n",
      "15 : torch.Size([768])\n",
      "16 : torch.Size([768])\n",
      "17 : torch.Size([256, 1024])\n",
      "18 : torch.Size([256])\n",
      "19 : torch.Size([2, 256])\n",
      "20 : torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(model.parameters()):\n",
    "    if p.requires_grad:\n",
    "        print(i, \":\", p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1526498800729,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "mVbrE_la4KNC",
    "outputId": "d90d7efa-e5c6-4ba0-e5e2-ad7b6a6b06f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-1.4277e-02 -1.4485e-02 -2.2928e-02  ...   1.6407e-02 -1.4513e-02 -2.7617e-02\n",
       " 4.0419e-03 -1.3952e-02 -2.2086e-02  ...  -1.3849e-02  2.3486e-02  1.1785e-02\n",
       " 1.1941e-02 -3.0250e-02  1.3061e-02  ...  -2.3700e-02  1.4854e-02  1.3456e-02\n",
       "                ...                   ⋱                   ...                \n",
       "-1.8124e-02 -9.7955e-04 -3.1669e-03  ...  -6.2509e-03 -9.4317e-03  2.3574e-02\n",
       " 2.5391e-02  2.2048e-02  2.6482e-02  ...  -2.7667e-02 -3.6992e-03 -2.4014e-02\n",
       "-2.7981e-03 -9.2835e-03  2.5175e-02  ...   1.7646e-02 -2.9831e-02  2.4577e-02\n",
       "[torch.cuda.FloatTensor of size 256x1024 (GPU 0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1526498802216,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "cXoRlKFZ4i4H",
    "outputId": "3d476a48-cc71-453c-a427-f6c9c3ebdfc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 3.0355e-03 -1.2961e-02  6.0064e-02  ...  -4.5771e-02  3.8890e-02 -2.4952e-02\n",
       " 3.7672e-02  5.5773e-02 -2.6081e-02  ...   2.9321e-02 -3.2315e-02  4.4971e-03\n",
       " 1.4381e-02  2.3699e-03 -3.3544e-02  ...  -4.8572e-02 -5.5734e-02 -3.7700e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0168e-02 -1.1434e-02 -2.9736e-02  ...  -3.2610e-02  5.6947e-02  4.0127e-02\n",
       " 3.2363e-02  4.6382e-02 -2.7200e-02  ...   4.1018e-02  2.3845e-02  4.2604e-02\n",
       " 4.2939e-02  3.3985e-02 -4.3579e-02  ...   3.8251e-02  1.0417e-02  4.2799e-02\n",
       "[torch.cuda.FloatTensor of size 768x128 (GPU 0)]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35987,
     "status": "ok",
     "timestamp": 1526498839422,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "7u1jwcR6rv8D",
    "outputId": "e6cf1761-215d-4e54-d834-0a4d38a270df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen1 size:  torch.Size([128, 40])\n",
      "outputs torch.Size([128, 2])\n",
      "targets torch.Size([128])\n",
      "loss Variable containing:\n",
      " 15.1438\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "========== performance on randomly selected 5000 samples from training data\n",
      "Correct:  3916\n",
      "tn, fp, fn, tp \n",
      " [3916    0 1084    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "========== performance on validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  3973\n",
      "tn, fp, fn, tp \n",
      " [3973    0 1027    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n"
     ]
    }
   ],
   "source": [
    "### test \n",
    "for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "    \n",
    "    # sen1 = batch * l\n",
    "    sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
    "    print(\"sen1 size: \", sen1.shape)\n",
    "    #input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in sen1]).view(sen1.size(0),-1)\n",
    "    #model.zero_grad()\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
    "    print('outputs', outputs.shape)\n",
    "    print('targets', targets.shape)\n",
    "    loss = criterion(outputs, targets)\n",
    "    print('loss', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    break\n",
    "    \n",
    "train_perf()\n",
    "validate_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 5862
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2540657,
     "status": "error",
     "timestamp": 1526501383026,
     "user": {
      "displayName": "Pengcheng Jia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112854971302097969837"
     },
     "user_tz": 240
    },
    "id": "EYyrQx1qsZUl",
    "outputId": "a89ea691-1f7f-47c2-d291-b2a6af5421c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [20/234], Mean Loss: 60.9731\n",
      "Epoch [1/150], Step [40/234], Mean Loss: 16.6609\n",
      "Epoch [1/150], Step [60/234], Mean Loss: 7.5086\n",
      "Epoch [1/150], Step [80/234], Mean Loss: 32.5770\n",
      "Epoch [1/150], Step [100/234], Mean Loss: 58.2470\n",
      "Epoch [1/150], Step [120/234], Mean Loss: 8.4096\n",
      "Epoch [1/150], Step [140/234], Mean Loss: 7.0080\n",
      "Epoch [1/150], Step [160/234], Mean Loss: 6.9316\n",
      "Epoch [1/150], Step [180/234], Mean Loss: 6.5598\n",
      "Epoch [1/150], Step [200/234], Mean Loss: 7.4286\n",
      "Epoch [1/150], Step [220/234], Mean Loss: 7.2922\n",
      "Epoch [2/150], Step [20/234], Mean Loss: 6.9981\n",
      "Epoch [2/150], Step [40/234], Mean Loss: 7.1628\n",
      "Epoch [2/150], Step [60/234], Mean Loss: 6.8713\n",
      "Epoch [2/150], Step [80/234], Mean Loss: 6.7820\n",
      "Epoch [2/150], Step [100/234], Mean Loss: 6.9583\n",
      "Epoch [2/150], Step [120/234], Mean Loss: 6.8134\n",
      "Epoch [2/150], Step [140/234], Mean Loss: 6.7407\n",
      "Epoch [2/150], Step [160/234], Mean Loss: 6.7690\n",
      "Epoch [2/150], Step [180/234], Mean Loss: 6.5154\n",
      "Epoch [2/150], Step [200/234], Mean Loss: 6.7647\n",
      "Epoch [2/150], Step [220/234], Mean Loss: 7.1653\n",
      "Epoch [3/150], Step [20/234], Mean Loss: 6.9174\n",
      "Epoch [3/150], Step [40/234], Mean Loss: 6.9348\n",
      "Epoch [3/150], Step [60/234], Mean Loss: 6.5487\n",
      "Epoch [3/150], Step [80/234], Mean Loss: 6.9608\n",
      "Epoch [3/150], Step [100/234], Mean Loss: 6.6568\n",
      "Epoch [3/150], Step [120/234], Mean Loss: 6.6211\n",
      "Epoch [3/150], Step [140/234], Mean Loss: 6.6771\n",
      "Epoch [3/150], Step [160/234], Mean Loss: 6.4599\n",
      "Epoch [3/150], Step [180/234], Mean Loss: 6.9546\n",
      "Epoch [3/150], Step [200/234], Mean Loss: 6.8330\n",
      "Epoch [3/150], Step [220/234], Mean Loss: 6.9941\n",
      "Epoch [4/150], Step [20/234], Mean Loss: 6.6560\n",
      "Epoch [4/150], Step [40/234], Mean Loss: 6.8194\n",
      "Epoch [4/150], Step [60/234], Mean Loss: 6.8689\n",
      "Epoch [4/150], Step [80/234], Mean Loss: 6.8433\n",
      "Epoch [4/150], Step [100/234], Mean Loss: 6.5741\n",
      "Epoch [4/150], Step [120/234], Mean Loss: 6.7969\n",
      "Epoch [4/150], Step [140/234], Mean Loss: 6.5539\n",
      "Epoch [4/150], Step [160/234], Mean Loss: 7.3867\n",
      "Epoch [4/150], Step [180/234], Mean Loss: 7.0593\n",
      "Epoch [4/150], Step [200/234], Mean Loss: 6.6472\n",
      "Epoch [4/150], Step [220/234], Mean Loss: 6.7379\n",
      "Epoch [5/150], Step [20/234], Mean Loss: 6.7746\n",
      "Epoch [5/150], Step [40/234], Mean Loss: 7.0400\n",
      "Epoch [5/150], Step [60/234], Mean Loss: 7.3026\n",
      "Epoch [5/150], Step [80/234], Mean Loss: 6.5804\n",
      "Epoch [5/150], Step [100/234], Mean Loss: 6.6025\n",
      "Epoch [5/150], Step [120/234], Mean Loss: 6.5996\n",
      "Epoch [5/150], Step [140/234], Mean Loss: 6.7190\n",
      "Epoch [5/150], Step [160/234], Mean Loss: 6.6147\n",
      "Epoch [5/150], Step [180/234], Mean Loss: 6.7504\n",
      "Epoch [5/150], Step [200/234], Mean Loss: 6.7572\n",
      "Epoch [5/150], Step [220/234], Mean Loss: 6.7160\n",
      "Epoch [6/150], Step [20/234], Mean Loss: 6.8396\n",
      "Epoch [6/150], Step [40/234], Mean Loss: 6.7066\n",
      "Epoch [6/150], Step [60/234], Mean Loss: 6.5382\n",
      "Epoch [6/150], Step [80/234], Mean Loss: 6.5700\n",
      "Epoch [6/150], Step [100/234], Mean Loss: 6.5046\n",
      "Epoch [6/150], Step [120/234], Mean Loss: 6.9449\n",
      "Epoch [6/150], Step [140/234], Mean Loss: 6.8900\n",
      "Epoch [6/150], Step [160/234], Mean Loss: 7.4384\n",
      "Epoch [6/150], Step [180/234], Mean Loss: 6.8235\n",
      "Epoch [6/150], Step [200/234], Mean Loss: 6.8854\n",
      "Epoch [6/150], Step [220/234], Mean Loss: 6.6032\n",
      "Epoch [7/150], Step [20/234], Mean Loss: 6.4733\n",
      "Epoch [7/150], Step [40/234], Mean Loss: 6.5082\n",
      "Epoch [7/150], Step [60/234], Mean Loss: 6.8477\n",
      "Epoch [7/150], Step [80/234], Mean Loss: 6.6799\n",
      "Epoch [7/150], Step [100/234], Mean Loss: 6.8097\n",
      "Epoch [7/150], Step [120/234], Mean Loss: 6.9599\n",
      "Epoch [7/150], Step [140/234], Mean Loss: 6.7788\n",
      "Epoch [7/150], Step [160/234], Mean Loss: 6.6533\n",
      "Epoch [7/150], Step [180/234], Mean Loss: 6.8484\n",
      "Epoch [7/150], Step [200/234], Mean Loss: 6.7050\n",
      "Epoch [7/150], Step [220/234], Mean Loss: 6.7449\n",
      "Epoch [8/150], Step [20/234], Mean Loss: 6.7349\n",
      "Epoch [8/150], Step [40/234], Mean Loss: 7.2275\n",
      "Epoch [8/150], Step [60/234], Mean Loss: 6.6842\n",
      "Epoch [8/150], Step [80/234], Mean Loss: 6.7872\n",
      "Epoch [8/150], Step [100/234], Mean Loss: 6.9305\n",
      "Epoch [8/150], Step [120/234], Mean Loss: 6.9008\n",
      "Epoch [8/150], Step [140/234], Mean Loss: 6.8165\n",
      "Epoch [8/150], Step [160/234], Mean Loss: 6.9912\n",
      "Epoch [8/150], Step [180/234], Mean Loss: 6.6993\n",
      "Epoch [8/150], Step [200/234], Mean Loss: 6.6081\n",
      "Epoch [8/150], Step [220/234], Mean Loss: 6.5694\n",
      "Epoch [9/150], Step [20/234], Mean Loss: 7.4820\n",
      "Epoch [9/150], Step [40/234], Mean Loss: 6.7380\n",
      "Epoch [9/150], Step [60/234], Mean Loss: 7.0063\n",
      "Epoch [9/150], Step [80/234], Mean Loss: 6.7708\n",
      "Epoch [9/150], Step [100/234], Mean Loss: 6.7582\n",
      "Epoch [9/150], Step [120/234], Mean Loss: 6.7917\n",
      "Epoch [9/150], Step [140/234], Mean Loss: 6.6742\n",
      "Epoch [9/150], Step [160/234], Mean Loss: 6.7372\n",
      "Epoch [9/150], Step [180/234], Mean Loss: 6.8444\n",
      "Epoch [9/150], Step [200/234], Mean Loss: 6.5304\n",
      "Epoch [9/150], Step [220/234], Mean Loss: 6.4457\n",
      "Epoch [10/150], Step [20/234], Mean Loss: 6.7325\n",
      "Epoch [10/150], Step [40/234], Mean Loss: 6.7667\n",
      "Epoch [10/150], Step [60/234], Mean Loss: 6.8063\n",
      "Epoch [10/150], Step [80/234], Mean Loss: 6.6647\n",
      "Epoch [10/150], Step [100/234], Mean Loss: 6.9489\n",
      "Epoch [10/150], Step [120/234], Mean Loss: 6.6108\n",
      "Epoch [10/150], Step [140/234], Mean Loss: 6.5638\n",
      "Epoch [10/150], Step [160/234], Mean Loss: 6.5928\n",
      "Epoch [10/150], Step [180/234], Mean Loss: 6.6807\n",
      "Epoch [10/150], Step [200/234], Mean Loss: 6.7863\n",
      "Epoch [10/150], Step [220/234], Mean Loss: 6.6523\n",
      "========== performance on randomly selected 5000 samples from training data\n",
      "Correct:  3896\n",
      "tn, fp, fn, tp \n",
      " [3896    0 1104    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "========== performance on validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  3973\n",
      "tn, fp, fn, tp \n",
      " [3973    0 1027    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "Epoch [11/150], Step [20/234], Mean Loss: 6.6734\n",
      "Epoch [11/150], Step [40/234], Mean Loss: 7.1429\n",
      "Epoch [11/150], Step [60/234], Mean Loss: 7.2135\n",
      "Epoch [11/150], Step [80/234], Mean Loss: 6.5440\n",
      "Epoch [11/150], Step [100/234], Mean Loss: 6.7476\n",
      "Epoch [11/150], Step [120/234], Mean Loss: 6.6975\n",
      "Epoch [11/150], Step [140/234], Mean Loss: 7.1095\n",
      "Epoch [11/150], Step [160/234], Mean Loss: 6.7437\n",
      "Epoch [11/150], Step [180/234], Mean Loss: 6.8401\n",
      "Epoch [11/150], Step [200/234], Mean Loss: 6.6917\n",
      "Epoch [11/150], Step [220/234], Mean Loss: 6.7649\n",
      "Epoch [12/150], Step [20/234], Mean Loss: 6.6881\n",
      "Epoch [12/150], Step [40/234], Mean Loss: 6.9102\n",
      "Epoch [12/150], Step [60/234], Mean Loss: 7.0092\n",
      "Epoch [12/150], Step [80/234], Mean Loss: 6.5706\n",
      "Epoch [12/150], Step [100/234], Mean Loss: 6.4731\n",
      "Epoch [12/150], Step [120/234], Mean Loss: 6.6012\n",
      "Epoch [12/150], Step [140/234], Mean Loss: 6.5597\n",
      "Epoch [12/150], Step [160/234], Mean Loss: 6.8910\n",
      "Epoch [12/150], Step [180/234], Mean Loss: 6.5826\n",
      "Epoch [12/150], Step [200/234], Mean Loss: 6.8258\n",
      "Epoch [12/150], Step [220/234], Mean Loss: 6.9943\n",
      "Epoch [13/150], Step [20/234], Mean Loss: 6.6560\n",
      "Epoch [13/150], Step [40/234], Mean Loss: 6.8050\n",
      "Epoch [13/150], Step [60/234], Mean Loss: 6.6452\n",
      "Epoch [13/150], Step [80/234], Mean Loss: 6.5517\n",
      "Epoch [13/150], Step [100/234], Mean Loss: 8.8755\n",
      "Epoch [13/150], Step [120/234], Mean Loss: 7.1346\n",
      "Epoch [13/150], Step [140/234], Mean Loss: 6.5778\n",
      "Epoch [13/150], Step [160/234], Mean Loss: 6.5148\n",
      "Epoch [13/150], Step [180/234], Mean Loss: 6.6456\n",
      "Epoch [13/150], Step [200/234], Mean Loss: 6.9485\n",
      "Epoch [13/150], Step [220/234], Mean Loss: 6.9858\n",
      "Epoch [14/150], Step [20/234], Mean Loss: 6.6992\n",
      "Epoch [14/150], Step [40/234], Mean Loss: 6.4760\n",
      "Epoch [14/150], Step [60/234], Mean Loss: 6.6822\n",
      "Epoch [14/150], Step [80/234], Mean Loss: 6.7376\n",
      "Epoch [14/150], Step [100/234], Mean Loss: 6.6701\n",
      "Epoch [14/150], Step [120/234], Mean Loss: 6.6768\n",
      "Epoch [14/150], Step [140/234], Mean Loss: 6.5558\n",
      "Epoch [14/150], Step [160/234], Mean Loss: 6.6770\n",
      "Epoch [14/150], Step [180/234], Mean Loss: 6.5422\n",
      "Epoch [14/150], Step [200/234], Mean Loss: 6.7542\n",
      "Epoch [14/150], Step [220/234], Mean Loss: 6.6168\n",
      "Epoch [15/150], Step [20/234], Mean Loss: 10.3312\n",
      "Epoch [15/150], Step [40/234], Mean Loss: 6.5304\n",
      "Epoch [15/150], Step [60/234], Mean Loss: 6.7806\n",
      "Epoch [15/150], Step [80/234], Mean Loss: 6.4816\n",
      "Epoch [15/150], Step [100/234], Mean Loss: 6.4797\n",
      "Epoch [15/150], Step [120/234], Mean Loss: 6.5957\n",
      "Epoch [15/150], Step [140/234], Mean Loss: 6.7113\n",
      "Epoch [15/150], Step [160/234], Mean Loss: 6.6203\n",
      "Epoch [15/150], Step [180/234], Mean Loss: 6.6019\n",
      "Epoch [15/150], Step [200/234], Mean Loss: 6.6148\n",
      "Epoch [15/150], Step [220/234], Mean Loss: 6.3049\n",
      "Epoch [16/150], Step [20/234], Mean Loss: 6.6986\n",
      "Epoch [16/150], Step [40/234], Mean Loss: 6.7907\n",
      "Epoch [16/150], Step [60/234], Mean Loss: 7.4185\n",
      "Epoch [16/150], Step [80/234], Mean Loss: 6.9105\n",
      "Epoch [16/150], Step [100/234], Mean Loss: 6.5241\n",
      "Epoch [16/150], Step [120/234], Mean Loss: 6.5506\n",
      "Epoch [16/150], Step [140/234], Mean Loss: 6.2351\n",
      "Epoch [16/150], Step [160/234], Mean Loss: 6.4198\n",
      "Epoch [16/150], Step [180/234], Mean Loss: 6.7046\n",
      "Epoch [16/150], Step [200/234], Mean Loss: 6.8310\n",
      "Epoch [16/150], Step [220/234], Mean Loss: 6.6166\n",
      "Epoch [17/150], Step [20/234], Mean Loss: 6.4776\n",
      "Epoch [17/150], Step [40/234], Mean Loss: 6.6531\n",
      "Epoch [17/150], Step [60/234], Mean Loss: 6.7808\n",
      "Epoch [17/150], Step [80/234], Mean Loss: 6.6637\n",
      "Epoch [17/150], Step [100/234], Mean Loss: 6.6351\n",
      "Epoch [17/150], Step [120/234], Mean Loss: 6.5589\n",
      "Epoch [17/150], Step [140/234], Mean Loss: 6.6205\n",
      "Epoch [17/150], Step [160/234], Mean Loss: 6.5689\n",
      "Epoch [17/150], Step [180/234], Mean Loss: 6.4431\n",
      "Epoch [17/150], Step [200/234], Mean Loss: 6.1554\n",
      "Epoch [17/150], Step [220/234], Mean Loss: 6.5367\n",
      "Epoch [18/150], Step [20/234], Mean Loss: 6.7842\n",
      "Epoch [18/150], Step [40/234], Mean Loss: 6.2657\n",
      "Epoch [18/150], Step [60/234], Mean Loss: 6.4418\n",
      "Epoch [18/150], Step [80/234], Mean Loss: 6.5233\n",
      "Epoch [18/150], Step [100/234], Mean Loss: 6.5310\n",
      "Epoch [18/150], Step [120/234], Mean Loss: 6.4682\n",
      "Epoch [18/150], Step [140/234], Mean Loss: 6.6635\n",
      "Epoch [18/150], Step [160/234], Mean Loss: 6.6702\n",
      "Epoch [18/150], Step [180/234], Mean Loss: 6.8297\n",
      "Epoch [18/150], Step [200/234], Mean Loss: 6.6845\n",
      "Epoch [18/150], Step [220/234], Mean Loss: 6.6091\n",
      "Epoch [19/150], Step [20/234], Mean Loss: 6.7076\n",
      "Epoch [19/150], Step [40/234], Mean Loss: 6.3394\n",
      "Epoch [19/150], Step [60/234], Mean Loss: 6.8091\n",
      "Epoch [19/150], Step [80/234], Mean Loss: 6.6195\n",
      "Epoch [19/150], Step [100/234], Mean Loss: 6.6703\n",
      "Epoch [19/150], Step [120/234], Mean Loss: 6.5272\n",
      "Epoch [19/150], Step [140/234], Mean Loss: 6.6290\n",
      "Epoch [19/150], Step [160/234], Mean Loss: 6.6290\n",
      "Epoch [19/150], Step [180/234], Mean Loss: 6.5060\n",
      "Epoch [19/150], Step [200/234], Mean Loss: 6.6320\n",
      "Epoch [19/150], Step [220/234], Mean Loss: 6.3606\n",
      "Epoch [20/150], Step [20/234], Mean Loss: 6.3823\n",
      "Epoch [20/150], Step [40/234], Mean Loss: 6.6724\n",
      "Epoch [20/150], Step [60/234], Mean Loss: 6.4758\n",
      "Epoch [20/150], Step [80/234], Mean Loss: 6.5468\n",
      "Epoch [20/150], Step [100/234], Mean Loss: 6.5400\n",
      "Epoch [20/150], Step [120/234], Mean Loss: 6.6108\n",
      "Epoch [20/150], Step [140/234], Mean Loss: 6.4782\n",
      "Epoch [20/150], Step [160/234], Mean Loss: 6.7372\n",
      "Epoch [20/150], Step [180/234], Mean Loss: 6.5542\n",
      "Epoch [20/150], Step [200/234], Mean Loss: 6.5155\n",
      "Epoch [20/150], Step [220/234], Mean Loss: 6.6464\n",
      "========== performance on randomly selected 5000 samples from training data\n",
      "Correct:  3871\n",
      "tn, fp, fn, tp \n",
      " [3871    0 1129    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "========== performance on validation data\n",
      "Correct:  3973\n",
      "tn, fp, fn, tp \n",
      " [3973    0 1027    0]\n",
      "precsion:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "Epoch [21/150], Step [20/234], Mean Loss: 6.6614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-88a724449eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Forward + Backward + Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen1_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen2_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-b7737cfdacef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sen1, sen2, sen1_lengths, sen2_lengths)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutputs_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_c1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msen1_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_c2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msen2_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_c1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_c1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-deebb2a28707>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_len)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;34m\"\"\"process using RNN\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mout_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"\"\"unsort: h\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             ))\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## TN FP\n",
    "## FN TP\n",
    "\n",
    "total_step = round(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    total_loss = []\n",
    "    \n",
    "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        sen1, sen2, targets,sen1_lengths, sen2_lengths = pad_to_batch(batch,source2index)\n",
    "        #model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        outputs = model(sen1, sen2, sen1_lengths, sen2_lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5) # gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Mean Loss: {:.4f}' \n",
    "                       .format(epoch+1, EPOCH, i+1, total_step, np.mean(total_loss)))\n",
    "            total_loss = []\n",
    "    \n",
    "    if (epoch + 1) %10 == 0:\n",
    "        train_perf()\n",
    "        validate_perf()\n",
    "    \n",
    "    #if RESCHEDULED == False and epoch  == EPOCH//4:\n",
    "    if (epoch + 1) %25 == 0:\n",
    "        LR *= 0.1\n",
    "        print(\"LR now is: \", LR)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        #RESCHEDULED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JqZkE5DsI1Y3"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'rnn-based.ckpt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Ali.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
